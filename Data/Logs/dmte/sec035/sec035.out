WARNING:tensorflow:From /home/liu/DMTE/code/DataSet.py:48: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
2019-04-18 20:43:55.448197: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
start loading data ...
1000000
data loaded succesffully ...
start training.......
epoch:  1  loss:  49555.263916015625
epoch:  2  loss:  36585.41015625
epoch:  3  loss:  22016.966674804688
epoch:  4  loss:  20853.931884765625
epoch:  5  loss:  20273.381713867188
epoch:  6  loss:  20091.644897460938
epoch:  7  loss:  19986.137329101562
epoch:  8  loss:  19906.903930664062
epoch:  9  loss:  19842.100830078125
epoch:  10  loss:  19783.946899414062
epoch:  11  loss:  19718.5068359375
epoch:  12  loss:  19654.488159179688
epoch:  13  loss:  19553.827026367188
epoch:  14  loss:  19485.158569335938
epoch:  15  loss:  19396.335327148438
epoch:  16  loss:  19261.24658203125
epoch:  17  loss:  19142.6572265625
epoch:  18  loss:  19002.938232421875
epoch:  19  loss:  18885.676513671875
epoch:  20  loss:  18758.478515625
epoch:  21  loss:  18633.837036132812
epoch:  22  loss:  18439.925048828125
epoch:  23  loss:  18380.837280273438
epoch:  24  loss:  18226.981323242188
epoch:  25  loss:  18174.771606445312
epoch:  26  loss:  18001.88134765625
epoch:  27  loss:  17949.324951171875
epoch:  28  loss:  17756.336547851562
epoch:  29  loss:  17749.220947265625
epoch:  30  loss:  17663.8740234375
epoch:  31  loss:  17548.295288085938
epoch:  32  loss:  17465.022705078125
epoch:  33  loss:  17268.486206054688
epoch:  34  loss:  17246.8427734375
epoch:  35  loss:  17163.501586914062
epoch:  36  loss:  17077.4697265625
epoch:  37  loss:  16957.128540039062
epoch:  38  loss:  16936.724975585938
epoch:  39  loss:  16858.382202148438
epoch:  40  loss:  16756.213623046875
epoch:  41  loss:  16709.263671875
epoch:  42  loss:  16615.039306640625
epoch:  43  loss:  16540.061645507812
epoch:  44  loss:  16479.916748046875
epoch:  45  loss:  16414.94384765625
epoch:  46  loss:  16325.563842773438
epoch:  47  loss:  16339.250854492188
epoch:  48  loss:  16140.391235351562
epoch:  49  loss:  16089.76513671875
epoch:  50  loss:  16011.670532226562
epoch:  51  loss:  16075.035400390625
epoch:  52  loss:  15911.86279296875
epoch:  53  loss:  16006.91259765625
epoch:  54  loss:  15815.946228027344
epoch:  55  loss:  15750.910217285156
epoch:  56  loss:  15834.963134765625
epoch:  57  loss:  15749.643615722656
epoch:  58  loss:  15539.607543945312
epoch:  59  loss:  15612.450256347656
epoch:  60  loss:  15519.705139160156
epoch:  61  loss:  15398.902160644531
epoch:  62  loss:  15469.565612792969
epoch:  63  loss:  15492.012451171875
epoch:  64  loss:  15301.548645019531
epoch:  65  loss:  15420.159423828125
epoch:  66  loss:  15130.494689941406
epoch:  67  loss:  15231.261169433594
epoch:  68  loss:  15274.252807617188
epoch:  69  loss:  15155.130432128906
epoch:  70  loss:  15112.293518066406
epoch:  71  loss:  15106.953247070312
epoch:  72  loss:  14993.212890625
epoch:  73  loss:  14912.6416015625
epoch:  74  loss:  14903.397277832031
epoch:  75  loss:  14919.935424804688
epoch:  76  loss:  14926.903076171875
epoch:  77  loss:  14930.099853515625
epoch:  78  loss:  14772.73779296875
epoch:  79  loss:  14783.570556640625
epoch:  80  loss:  14759.999877929688
epoch:  81  loss:  14692.376281738281
epoch:  82  loss:  14708.92431640625
epoch:  83  loss:  14818.760864257812
epoch:  84  loss:  14726.650512695312
epoch:  85  loss:  14635.78955078125
epoch:  86  loss:  14757.3642578125
epoch:  87  loss:  14617.469116210938
epoch:  88  loss:  14648.144714355469
epoch:  89  loss:  14619.306640625
epoch:  90  loss:  14642.311767578125
epoch:  91  loss:  14610.56396484375
epoch:  92  loss:  14586.745849609375
epoch:  93  loss:  14543.265991210938
epoch:  94  loss:  14355.076721191406
epoch:  95  loss:  14420.478393554688
epoch:  96  loss:  14319.698181152344
epoch:  97  loss:  14272.732971191406
epoch:  98  loss:  14454.583190917969
epoch:  99  loss:  14487.145202636719
epoch:  100  loss:  14418.292785644531
epoch:  101  loss:  14366.790710449219
epoch:  102  loss:  14271.248962402344
epoch:  103  loss:  14293.859924316406
epoch:  104  loss:  14352.506408691406
epoch:  105  loss:  14381.07861328125
epoch:  106  loss:  14393.208251953125
epoch:  107  loss:  14369.941772460938
epoch:  108  loss:  14168.2880859375
epoch:  109  loss:  14113.241577148438
epoch:  110  loss:  14113.705627441406
epoch:  111  loss:  13996.089782714844
epoch:  112  loss:  14169.985046386719
epoch:  113  loss:  14161.239929199219
epoch:  114  loss:  14183.152404785156
epoch:  115  loss:  14280.7763671875
epoch:  116  loss:  14112.843872070312
epoch:  117  loss:  14054.033020019531
epoch:  118  loss:  14012.240478515625
epoch:  119  loss:  13932.51171875
epoch:  120  loss:  13976.057250976562
epoch:  121  loss:  13954.537963867188
epoch:  122  loss:  13948.038940429688
epoch:  123  loss:  13863.093505859375
epoch:  124  loss:  14041.164489746094
epoch:  125  loss:  13946.287780761719
epoch:  126  loss:  13885.827087402344
epoch:  127  loss:  13877.298217773438
epoch:  128  loss:  13952.67138671875
epoch:  129  loss:  13901.695922851562
epoch:  130  loss:  13933.727844238281
epoch:  131  loss:  13913.940612792969
epoch:  132  loss:  13810.54541015625
epoch:  133  loss:  13999.270141601562
epoch:  134  loss:  14005.345581054688
epoch:  135  loss:  13898.571105957031
epoch:  136  loss:  13992.474975585938
epoch:  137  loss:  13786.599304199219
epoch:  138  loss:  13840.454162597656
epoch:  139  loss:  13846.862731933594
epoch:  140  loss:  13852.93798828125
epoch:  141  loss:  13833.855773925781
epoch:  142  loss:  13820.644653320312
epoch:  143  loss:  13819.142761230469
epoch:  144  loss:  13675.900146484375
epoch:  145  loss:  13857.882690429688
epoch:  146  loss:  13730.811950683594
epoch:  147  loss:  13791.76904296875
epoch:  148  loss:  13713.432434082031
epoch:  149  loss:  13699.775390625
epoch:  150  loss:  13696.448181152344
epoch:  151  loss:  13666.884094238281
epoch:  152  loss:  13770.929809570312
epoch:  153  loss:  13646.447265625
epoch:  154  loss:  13646.810546875
epoch:  155  loss:  13758.545654296875
epoch:  156  loss:  13679.600646972656
epoch:  157  loss:  13563.420959472656
epoch:  158  loss:  13787.779235839844
epoch:  159  loss:  13383.80029296875
epoch:  160  loss:  13571.188110351562
epoch:  161  loss:  13661.694458007812
epoch:  162  loss:  13616.349487304688
epoch:  163  loss:  13826.165771484375
epoch:  164  loss:  13621.4765625
epoch:  165  loss:  13693.447509765625
epoch:  166  loss:  13496.383850097656
epoch:  167  loss:  13674.868347167969
epoch:  168  loss:  13555.531921386719
epoch:  169  loss:  13487.82958984375
epoch:  170  loss:  13575.803771972656
epoch:  171  loss:  13531.664672851562
epoch:  172  loss:  13658.31396484375
epoch:  173  loss:  13572.920959472656
epoch:  174  loss:  13656.136108398438
epoch:  175  loss:  13620.330932617188
epoch:  176  loss:  13369.562927246094
epoch:  177  loss:  13540.141235351562
epoch:  178  loss:  13438.022094726562
epoch:  179  loss:  13425.844604492188
epoch:  180  loss:  13545.549377441406
epoch:  181  loss:  13599.402465820312
epoch:  182  loss:  13594.266357421875
epoch:  183  loss:  13587.06787109375
epoch:  184  loss:  13563.247253417969
epoch:  185  loss:  13368.203552246094
epoch:  186  loss:  13528.296142578125
epoch:  187  loss:  13523.655639648438
epoch:  188  loss:  13578.496459960938
epoch:  189  loss:  13420.901062011719
epoch:  190  loss:  13410.446350097656
epoch:  191  loss:  13255.889343261719
epoch:  192  loss:  13518.9794921875
epoch:  193  loss:  13509.907653808594
epoch:  194  loss:  13445.717468261719
epoch:  195  loss:  13431.925903320312
epoch:  196  loss:  13384.264831542969
epoch:  197  loss:  13573.106018066406
epoch:  198  loss:  13366.74609375
epoch:  199  loss:  13442.395629882812
epoch:  200  loss:  13492.428100585938
('Valid edges for AUC is', 9332)
('AUC =', 0.9564937848264038)
