WARNING:tensorflow:From /home/liu/DMTE/code/DataSet.py:48: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
2019-04-18 19:12:20.413710: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
start loading data ...
1000000
data loaded succesffully ...
start training.......
epoch:  1  loss:  89125.4990234375
epoch:  2  loss:  49402.18273925781
epoch:  3  loss:  48246.28601074219
epoch:  4  loss:  47984.3212890625
epoch:  5  loss:  47733.32275390625
epoch:  6  loss:  47398.664306640625
epoch:  7  loss:  46898.63000488281
epoch:  8  loss:  46334.521484375
epoch:  9  loss:  45693.14343261719
epoch:  10  loss:  45019.746826171875
epoch:  11  loss:  44389.58642578125
epoch:  12  loss:  43835.93957519531
epoch:  13  loss:  43278.20520019531
epoch:  14  loss:  42534.503173828125
epoch:  15  loss:  42058.61804199219
epoch:  16  loss:  41564.894287109375
epoch:  17  loss:  41011.06628417969
epoch:  18  loss:  40442.576171875
epoch:  19  loss:  40100.892333984375
epoch:  20  loss:  39460.69055175781
epoch:  21  loss:  39178.94140625
epoch:  22  loss:  38890.36474609375
epoch:  23  loss:  38188.586975097656
epoch:  24  loss:  37954.86962890625
epoch:  25  loss:  37719.82501220703
epoch:  26  loss:  37277.38641357422
epoch:  27  loss:  36932.64050292969
epoch:  28  loss:  36721.561584472656
epoch:  29  loss:  36533.000915527344
epoch:  30  loss:  36104.26690673828
epoch:  31  loss:  35709.48205566406
epoch:  32  loss:  35267.081604003906
epoch:  33  loss:  35605.56317138672
epoch:  34  loss:  35198.240234375
epoch:  35  loss:  35080.801818847656
epoch:  36  loss:  34617.05847167969
epoch:  37  loss:  34537.904357910156
epoch:  38  loss:  34325.959899902344
epoch:  39  loss:  34369.894958496094
epoch:  40  loss:  34188.36999511719
epoch:  41  loss:  33874.450744628906
epoch:  42  loss:  33722.248962402344
epoch:  43  loss:  33697.160217285156
epoch:  44  loss:  33522.81475830078
epoch:  45  loss:  33488.742126464844
epoch:  46  loss:  33450.28143310547
epoch:  47  loss:  33179.22277832031
epoch:  48  loss:  33030.18591308594
epoch:  49  loss:  33098.10028076172
epoch:  50  loss:  32805.362854003906
epoch:  51  loss:  32946.15203857422
epoch:  52  loss:  33013.78820800781
epoch:  53  loss:  33198.455993652344
epoch:  54  loss:  32707.774353027344
epoch:  55  loss:  32631.615600585938
epoch:  56  loss:  32370.66229248047
epoch:  57  loss:  32393.710998535156
epoch:  58  loss:  32291.570373535156
epoch:  59  loss:  32333.602966308594
epoch:  60  loss:  32078.004272460938
epoch:  61  loss:  31997.6318359375
epoch:  62  loss:  32107.434692382812
epoch:  63  loss:  32050.40399169922
epoch:  64  loss:  32250.328491210938
epoch:  65  loss:  32149.446899414062
epoch:  66  loss:  32049.54296875
epoch:  67  loss:  32224.002685546875
epoch:  68  loss:  31660.346069335938
epoch:  69  loss:  31831.62725830078
epoch:  70  loss:  31527.4130859375
epoch:  71  loss:  31675.66534423828
epoch:  72  loss:  31669.254150390625
epoch:  73  loss:  31320.379638671875
epoch:  74  loss:  31531.397033691406
epoch:  75  loss:  31442.31719970703
epoch:  76  loss:  31476.22021484375
epoch:  77  loss:  31592.932678222656
epoch:  78  loss:  31360.37939453125
epoch:  79  loss:  31203.900329589844
epoch:  80  loss:  31240.031494140625
epoch:  81  loss:  31444.359375
epoch:  82  loss:  31288.56201171875
epoch:  83  loss:  31138.883178710938
epoch:  84  loss:  31289.015380859375
epoch:  85  loss:  31205.772033691406
epoch:  86  loss:  31131.490356445312
epoch:  87  loss:  31119.888793945312
epoch:  88  loss:  31016.49627685547
epoch:  89  loss:  31078.41571044922
epoch:  90  loss:  30970.222534179688
epoch:  91  loss:  31062.006408691406
epoch:  92  loss:  30828.124877929688
epoch:  93  loss:  30986.875244140625
epoch:  94  loss:  30695.773193359375
epoch:  95  loss:  30560.30841064453
epoch:  96  loss:  31039.528564453125
epoch:  97  loss:  30734.579956054688
epoch:  98  loss:  30973.632446289062
epoch:  99  loss:  30989.79833984375
epoch:  100  loss:  30893.591674804688
epoch:  101  loss:  30682.781127929688
epoch:  102  loss:  30684.34161376953
epoch:  103  loss:  30687.308349609375
epoch:  104  loss:  30657.456604003906
epoch:  105  loss:  30597.527587890625
epoch:  106  loss:  30399.827575683594
epoch:  107  loss:  30524.06494140625
epoch:  108  loss:  30697.919982910156
epoch:  109  loss:  30803.591064453125
epoch:  110  loss:  30646.22900390625
epoch:  111  loss:  30557.0087890625
epoch:  112  loss:  30639.120849609375
epoch:  113  loss:  30520.05926513672
epoch:  114  loss:  30516.29473876953
epoch:  115  loss:  30265.866760253906
epoch:  116  loss:  30214.907287597656
epoch:  117  loss:  30220.111938476562
epoch:  118  loss:  30462.609130859375
epoch:  119  loss:  30234.135131835938
epoch:  120  loss:  30450.613525390625
epoch:  121  loss:  30039.730346679688
epoch:  122  loss:  30167.83380126953
epoch:  123  loss:  30429.173583984375
epoch:  124  loss:  30448.429565429688
epoch:  125  loss:  30327.57745361328
epoch:  126  loss:  30257.36846923828
epoch:  127  loss:  30201.941345214844
epoch:  128  loss:  30069.248596191406
epoch:  129  loss:  30322.984252929688
epoch:  130  loss:  30497.91583251953
epoch:  131  loss:  29894.275512695312
epoch:  132  loss:  30169.98028564453
epoch:  133  loss:  30198.78631591797
epoch:  134  loss:  30124.90704345703
epoch:  135  loss:  29923.164001464844
epoch:  136  loss:  29931.813903808594
epoch:  137  loss:  30326.729553222656
epoch:  138  loss:  30222.998046875
epoch:  139  loss:  30008.141723632812
epoch:  140  loss:  29764.223022460938
epoch:  141  loss:  30052.97235107422
epoch:  142  loss:  30039.044189453125
epoch:  143  loss:  30066.31591796875
epoch:  144  loss:  29862.56365966797
epoch:  145  loss:  29629.001342773438
epoch:  146  loss:  29962.2509765625
epoch:  147  loss:  29737.29412841797
epoch:  148  loss:  29704.681518554688
epoch:  149  loss:  29883.880859375
epoch:  150  loss:  29872.140197753906
epoch:  151  loss:  29694.669372558594
epoch:  152  loss:  29720.19842529297
epoch:  153  loss:  29899.969604492188
epoch:  154  loss:  29779.07537841797
epoch:  155  loss:  30031.508178710938
epoch:  156  loss:  29574.116333007812
epoch:  157  loss:  29936.468017578125
epoch:  158  loss:  29870.257080078125
epoch:  159  loss:  29937.787658691406
epoch:  160  loss:  29551.513732910156
epoch:  161  loss:  29831.43145751953
epoch:  162  loss:  29982.15118408203
epoch:  163  loss:  29848.89501953125
epoch:  164  loss:  29885.32196044922
epoch:  165  loss:  29566.74462890625
epoch:  166  loss:  29536.7021484375
epoch:  167  loss:  29528.732482910156
epoch:  168  loss:  29589.588806152344
epoch:  169  loss:  29640.4560546875
epoch:  170  loss:  29559.414611816406
epoch:  171  loss:  29711.0791015625
epoch:  172  loss:  29821.635314941406
epoch:  173  loss:  29531.838439941406
epoch:  174  loss:  29448.51434326172
epoch:  175  loss:  29313.731079101562
epoch:  176  loss:  29629.023559570312
epoch:  177  loss:  29918.812072753906
epoch:  178  loss:  29454.618041992188
epoch:  179  loss:  29627.228637695312
epoch:  180  loss:  29563.619873046875
epoch:  181  loss:  29550.506286621094
epoch:  182  loss:  29623.785400390625
epoch:  183  loss:  29211.98486328125
epoch:  184  loss:  29867.054443359375
epoch:  185  loss:  29912.176025390625
epoch:  186  loss:  29291.79052734375
epoch:  187  loss:  29540.59930419922
epoch:  188  loss:  29511.336303710938
epoch:  189  loss:  29427.300170898438
epoch:  190  loss:  29679.572021484375
epoch:  191  loss:  29655.269287109375
epoch:  192  loss:  29145.88653564453
epoch:  193  loss:  29568.899658203125
epoch:  194  loss:  29050.820678710938
epoch:  195  loss:  29358.89288330078
epoch:  196  loss:  29669.78125
epoch:  197  loss:  29196.08319091797
epoch:  198  loss:  29329.79571533203
epoch:  199  loss:  29580.84881591797
epoch:  200  loss:  29247.91680908203
('Valid edges for AUC is', 1655)
('AUC =', 0.9347432024169184)
