WARNING:tensorflow:From /home/liu/DMTE/code/DataSet.py:48: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: __init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
WARNING:tensorflow:From /home/liu/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tensorflow/transform or tf.data.
2019-03-21 10:36:22.238374: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
1000000
start training.......
epoch:  1  loss:  55944.46435546875
epoch:  2  loss:  43174.55798339844
epoch:  3  loss:  23628.865966796875
epoch:  4  loss:  22708.017822265625
epoch:  5  loss:  22501.020874023438
epoch:  6  loss:  22372.12744140625
epoch:  7  loss:  22287.598754882812
epoch:  8  loss:  22197.10400390625
epoch:  9  loss:  22082.7109375
epoch:  10  loss:  21970.063232421875
epoch:  11  loss:  21865.387451171875
epoch:  12  loss:  21698.492797851562
epoch:  13  loss:  21521.152465820312
epoch:  14  loss:  21318.199462890625
epoch:  15  loss:  21120.019897460938
epoch:  16  loss:  20810.81298828125
epoch:  17  loss:  20563.99755859375
epoch:  18  loss:  20371.70166015625
epoch:  19  loss:  20174.055297851562
epoch:  20  loss:  20061.848266601562
epoch:  21  loss:  19740.226318359375
epoch:  22  loss:  19675.628173828125
epoch:  23  loss:  19612.232788085938
epoch:  24  loss:  19617.765258789062
epoch:  25  loss:  19478.470581054688
epoch:  26  loss:  19314.955078125
epoch:  27  loss:  19224.423095703125
epoch:  28  loss:  19185.186767578125
epoch:  29  loss:  19090.006469726562
epoch:  30  loss:  18948.504638671875
epoch:  31  loss:  18905.252075195312
epoch:  32  loss:  18737.208251953125
epoch:  33  loss:  18762.855834960938
epoch:  34  loss:  18700.34228515625
epoch:  35  loss:  18693.505126953125
epoch:  36  loss:  18530.086303710938
epoch:  37  loss:  18499.35546875
epoch:  38  loss:  18524.812744140625
epoch:  39  loss:  18325.750366210938
epoch:  40  loss:  18195.916259765625
epoch:  41  loss:  18375.485473632812
epoch:  42  loss:  18265.498046875
epoch:  43  loss:  18286.622802734375
epoch:  44  loss:  18070.670288085938
epoch:  45  loss:  18061.824829101562
epoch:  46  loss:  17910.712768554688
epoch:  47  loss:  18008.440551757812
epoch:  48  loss:  17947.285278320312
epoch:  49  loss:  17819.531127929688
epoch:  50  loss:  17827.471923828125
epoch:  51  loss:  17742.77752685547
epoch:  52  loss:  17777.502197265625
epoch:  53  loss:  17741.102661132812
epoch:  54  loss:  17669.15301513672
epoch:  55  loss:  17752.569091796875
epoch:  56  loss:  17549.867553710938
epoch:  57  loss:  17480.468627929688
epoch:  58  loss:  17455.321838378906
epoch:  59  loss:  17498.734252929688
epoch:  60  loss:  17455.364013671875
epoch:  61  loss:  17345.97265625
epoch:  62  loss:  17351.352966308594
epoch:  63  loss:  17303.305603027344
epoch:  64  loss:  17251.118713378906
epoch:  65  loss:  17219.107177734375
epoch:  66  loss:  17222.3251953125
epoch:  67  loss:  17136.900512695312
epoch:  68  loss:  17227.449829101562
epoch:  69  loss:  17063.527587890625
epoch:  70  loss:  17090.5068359375
epoch:  71  loss:  17041.046936035156
epoch:  72  loss:  16926.744140625
epoch:  73  loss:  16942.863830566406
epoch:  74  loss:  17095.104125976562
epoch:  75  loss:  16909.16082763672
epoch:  76  loss:  16781.267639160156
epoch:  77  loss:  16816.671875
epoch:  78  loss:  16994.51580810547
epoch:  79  loss:  16849.568725585938
epoch:  80  loss:  16739.629272460938
epoch:  81  loss:  16758.057495117188
epoch:  82  loss:  16838.89520263672
epoch:  83  loss:  16822.80596923828
epoch:  84  loss:  16737.931030273438
epoch:  85  loss:  16711.46514892578
epoch:  86  loss:  16610.99609375
epoch:  87  loss:  16656.159790039062
epoch:  88  loss:  16703.919494628906
epoch:  89  loss:  16639.26141357422
epoch:  90  loss:  16626.6064453125
epoch:  91  loss:  16550.985229492188
epoch:  92  loss:  16591.156372070312
epoch:  93  loss:  16589.964233398438
epoch:  94  loss:  16515.95556640625
epoch:  95  loss:  16410.562377929688
epoch:  96  loss:  16402.59051513672
epoch:  97  loss:  16361.932006835938
epoch:  98  loss:  16394.37176513672
epoch:  99  loss:  16379.730224609375
epoch:  100  loss:  16419.29461669922
epoch:  101  loss:  16480.081481933594
epoch:  102  loss:  16416.783081054688
epoch:  103  loss:  16460.332275390625
epoch:  104  loss:  16380.273681640625
epoch:  105  loss:  16310.672302246094
epoch:  106  loss:  16365.84814453125
epoch:  107  loss:  16300.746398925781
epoch:  108  loss:  16271.504211425781
epoch:  109  loss:  16250.707458496094
epoch:  110  loss:  16334.328002929688
epoch:  111  loss:  16192.605407714844
epoch:  112  loss:  16243.748779296875
epoch:  113  loss:  16138.669555664062
epoch:  114  loss:  16179.406677246094
epoch:  115  loss:  16221.982238769531
epoch:  116  loss:  16234.336547851562
epoch:  117  loss:  16120.182800292969
epoch:  118  loss:  16170.676086425781
epoch:  119  loss:  16152.594543457031
epoch:  120  loss:  16228.352844238281
epoch:  121  loss:  16056.805969238281
epoch:  122  loss:  16189.990234375
epoch:  123  loss:  16072.374145507812
epoch:  124  loss:  15975.052429199219
epoch:  125  loss:  16175.570190429688
epoch:  126  loss:  16113.263793945312
epoch:  127  loss:  16100.612121582031
epoch:  128  loss:  16151.383117675781
epoch:  129  loss:  16174.430419921875
epoch:  130  loss:  16113.839111328125
epoch:  131  loss:  16122.496826171875
epoch:  132  loss:  16130.12646484375
epoch:  133  loss:  15944.575927734375
epoch:  134  loss:  15968.326721191406
epoch:  135  loss:  16042.750122070312
epoch:  136  loss:  15968.109619140625
epoch:  137  loss:  15950.483154296875
epoch:  138  loss:  15923.224548339844
epoch:  139  loss:  15974.862182617188
epoch:  140  loss:  16145.919799804688
epoch:  141  loss:  16105.219665527344
epoch:  142  loss:  15955.798767089844
epoch:  143  loss:  16075.084045410156
epoch:  144  loss:  16045.212707519531
epoch:  145  loss:  15941.907897949219
epoch:  146  loss:  15944.942260742188
epoch:  147  loss:  15863.930419921875
epoch:  148  loss:  15922.92236328125
epoch:  149  loss:  15978.452087402344
epoch:  150  loss:  15995.276489257812
epoch:  151  loss:  15918.789123535156
epoch:  152  loss:  15950.634826660156
epoch:  153  loss:  16042.068908691406
epoch:  154  loss:  15864.572265625
epoch:  155  loss:  15861.025817871094
epoch:  156  loss:  15908.064514160156
epoch:  157  loss:  15952.925476074219
epoch:  158  loss:  15804.701599121094
epoch:  159  loss:  15821.237243652344
epoch:  160  loss:  15796.023376464844
epoch:  161  loss:  15691.915832519531
epoch:  162  loss:  15742.111633300781
epoch:  163  loss:  15941.75146484375
epoch:  164  loss:  15690.505187988281
epoch:  165  loss:  15798.905883789062
epoch:  166  loss:  15821.009155273438
epoch:  167  loss:  15777.588439941406
epoch:  168  loss:  15811.370178222656
epoch:  169  loss:  15846.760986328125
epoch:  170  loss:  15867.896423339844
epoch:  171  loss:  15709.257141113281
epoch:  172  loss:  15713.061401367188
epoch:  173  loss:  15725.086364746094
epoch:  174  loss:  15739.701721191406
epoch:  175  loss:  15694.204284667969
epoch:  176  loss:  15783.77880859375
epoch:  177  loss:  15841.589477539062
epoch:  178  loss:  15626.881286621094
epoch:  179  loss:  15789.836486816406
epoch:  180  loss:  15787.580749511719
epoch:  181  loss:  15702.727722167969
epoch:  182  loss:  15638.347106933594
epoch:  183  loss:  15705.337219238281
epoch:  184  loss:  15657.544799804688
epoch:  185  loss:  15761.217102050781
epoch:  186  loss:  15746.071228027344
epoch:  187  loss:  15738.235595703125
epoch:  188  loss:  15789.421020507812
epoch:  189  loss:  15789.020202636719
epoch:  190  loss:  15667.477233886719
epoch:  191  loss:  15684.7841796875
epoch:  192  loss:  15695.357421875
epoch:  193  loss:  15651.549987792969
epoch:  194  loss:  15700.475891113281
epoch:  195  loss:  15677.795837402344
epoch:  196  loss:  15622.100402832031
epoch:  197  loss:  15783.380493164062
epoch:  198  loss:  15563.651977539062
epoch:  199  loss:  15679.719421386719
epoch:  200  loss:  15703.707275390625
0.960725075529
